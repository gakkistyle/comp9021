{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not need to be executed if\n",
    "# ~/.ipython/profile_default/ipython_config.py\n",
    "# exists and contains:\n",
    "# get_config().InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two kinds of symbols, in finite numbers: nonterminals, usually represented as uppercase letters, and terminals, usually represented as lowercase letters, one of which, denoted by $\\varepsilon$, is special and represents the empty symbol. A production rule maps a nonterminal to a finite sequence of terminals and nonterminals, the former being the left hand side of the rule, the latter its right hand side. A context free grammar (CFG) is a finite number of production rules together with a distinguished nonterminal, referred to as the starting symbol.\n",
    "\n",
    "Let $\\mathcal G$ denote a context free grammar. The set of production rules of $\\mathcal G$ is usually represented as follows. Let $\\alpha$ be a nonterminal that is the left hand side of at least one of $\\mathcal G$'s production rules. If only one production rule of $\\mathcal G$ has $\\alpha$ as left hand side, then one line of the represention is \"$\\alpha\\rightarrow\\Lambda$\" with $\\Lambda$ the right hand side of that rule. If $n$ production rules of $\\mathcal G$ have $\\alpha$ as left hand side with $n>1$, then one line of the represention is \"$\\alpha\\rightarrow\\Lambda_1|\\dots|\\Lambda_n$\" with $\\Lambda_1$, ..., $\\Lambda_n$ the right hand sides of those $n$ rules, in an arbitrary order.\n",
    "\n",
    "A derivation of a $\\mathcal G$ is a sequence of the form \"$\\Lambda_0\\rightarrow\\dots\\rightarrow\\Lambda_n$\" for some $n\\geq 0$ where:\n",
    "* $\\Lambda_0$ is $\\mathcal G$'s starting symbol;\n",
    "* for all $p<n$, $\\Lambda_{p+1}$ is obtained from $\\Lambda_p$ by replacing an occurrence in $\\Lambda_p$ of a nonterminal $\\alpha$ by the right hand side of a production rule of $\\mathcal G$ whose left hand side is $\\alpha$.\n",
    "\n",
    "$\\Lambda_n$ is said to be generated by $\\mathcal G$. If nothing but terminals occur in $\\Lambda_n$, then the derivation cannot be extended to a longer derivation.\n",
    "\n",
    "The language of $\\mathcal G$ is the set of finite sequences of terminals generated by $\\mathcal G$.\n",
    "\n",
    "A derivation \"$\\Lambda_0\\rightarrow\\dots\\rightarrow\\Lambda_n$\" is a leftmost derivation if for all $p<n$, the leftmost occurrence in $\\Lambda_p$ of a nonterminal is the one that is replaced by the right hand side of a production rule of $\\mathcal G$ to yield $\\Lambda_{p+1}$. It can be shown that each member of the language of $\\mathcal G$ ends some leftmost derivation of $\\mathcal G$: the language of $\\mathcal G$ allows derivations to be restricted to leftmost ones.\n",
    "\n",
    "Following are four examples of context free grammars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palindromes over $\\{a,b\\}$\n",
    "\n",
    "Besides $\\varepsilon$, the terminals are $a$ and $b$. The starting symbol is the unique nonterminal, $S$. The grammar is represented as follows.\n",
    "\n",
    "$S \\rightarrow aSa\\ |\\ bSb\\ |\\ a\\ |\\ b\\ |\\ \\varepsilon$\n",
    "\n",
    "It is easy to see that the language of this grammar is the set of finite sequences of $a$'s and $b$'s that read identically from left to right and from right to left (palindromes over $\\{a,b\\}$): the empty sequence, $a$, $b$, $aa$, $bb$, $aaa$, $bbb$, $aba$, $bab$...\n",
    "\n",
    "Clearly, every palindrome $\\Lambda$ over $\\{a,b\\}$ ends a unique derivation, that involves nothing but sequences where $S$ occurs once and only once, except for the final sequence, $\\Lambda$. Hence all derivations are leftmost. For instance, the unique derivation of the palindrome $abbbaaaabbba$ is:\n",
    "\n",
    "$S \\rightarrow aSa \\rightarrow abSba \\rightarrow abbSbba \\rightarrow abbbSbbba \\rightarrow abbbaSabbba \\rightarrow abbbaaSaabbba \\rightarrow abbbaaaabbba$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Members of the set $\\{b^na^mb^{2n}\\mid n\\geq 0, m\\geq 0\\}$\n",
    "\n",
    "Besides $\\varepsilon$, the terminals are $a$ and $b$. The nonterminals are $S$ and $A$, $S$ being the starting symbol. The grammar is represented as follows.\n",
    "\n",
    "$S \\rightarrow bSbb\\ |\\ A$  \n",
    "$A \\rightarrow aA\\ |\\ \\varepsilon$\n",
    "\n",
    "It is easy to see that the language of this grammar is the set of finite sequences of $a$'s and $b$'s of the form $b^na^mb^{2n}$, $n\\geq 0$, $m\\geq 0$.\n",
    "\n",
    "Clearly, every member $\\Lambda$ of $\\{b^na^mb^{2n}\\mid n\\geq 0, m\\geq 0\\}$ ends a unique derivation, that involves nothing but sequences where either $S$ of $A$ occurs once and only once, except for the final sequence, $\\Lambda$. Hence all derivations are leftmost. For instance, the unique derivations of the empty sequence, $bbbbbb$, $aaa$ and $bbbaabbbbbb$ are:\n",
    "\n",
    "$S \\rightarrow A \\rightarrow \\varepsilon$\n",
    "\n",
    "$S \\rightarrow bSbb \\rightarrow bbSbbbb \\rightarrow bbAbbbb \\rightarrow bbbbbb$\n",
    "\n",
    "$S\\rightarrow A \\rightarrow aA \\rightarrow aaA \\rightarrow aaaA \\rightarrow aaa$\n",
    "\n",
    "$S \\rightarrow bSbb \\rightarrow bbSbbbb \\rightarrow bbbSbbbbbb \\rightarrow bbbAbbbbbb \\rightarrow bbbaAbbbbbb \\rightarrow bbbaaAbbbbbb \\rightarrow bbbaabbbbbb$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-formed nested parentheses and square brackets\n",
    "\n",
    "Here $\\varepsilon$ is not used. The terminals are $($, $)$, $[$ and $]$. The starting symbol is the unique nonterminal, $S$. The grammar is represented as follows.\n",
    "\n",
    "$S \\rightarrow SS$  \n",
    "$S \\rightarrow ()$  \n",
    "$S \\rightarrow (S)$  \n",
    "$S \\rightarrow []$  \n",
    "$S \\rightarrow [S]$\n",
    "\n",
    "It is easy to see that the language of this grammar is the set of well-formed nested parentheses and square brackets. For instance, $()[]$ is a member of this set; it has two derivations:\n",
    "* $S\\rightarrow SS\\rightarrow ()S\\rightarrow ()[]$, which is leftmost;\n",
    "* $S\\rightarrow SS\\rightarrow S[]\\rightarrow ()[]$, which is not leftmost.\n",
    "\n",
    "Some well-formed nested parentheses and square brackets have many leftmost derivations. For instance, $()()()$ has two:\n",
    "* $S \\rightarrow SS \\rightarrow ()S \\rightarrow ()SS \\rightarrow ()()S \\rightarrow ()()()$\n",
    "* $S \\rightarrow SS \\rightarrow SSS \\rightarrow ()SS \\rightarrow ()()S \\rightarrow ()()()$\n",
    "\n",
    "For another example, the leftmost derivation of $([[[()()[][]]]([])])$ is:\n",
    "\n",
    "$S \\rightarrow (S) \\rightarrow ([S]) \\rightarrow ([SS]) \\rightarrow ([[S]S]) \\rightarrow ([[[S]]S]) \\rightarrow ([[[SS]]S]) \\rightarrow ([[[SSS]]S]) \\rightarrow ([[[SSSS]]S]) \\rightarrow ([[[()SSS]]S]) \\rightarrow ([[[()()SS]]S]) \\rightarrow ([[[()()[]S]]S]) \\rightarrow ([[[()()[][]]]S]) \\rightarrow ([[[()()[][]]](S)]) \\rightarrow ([[[()()[][]]]([])])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings over $\\{a,b\\}$ with an unequal number of $a$'s and $b$'s\n",
    "\n",
    "Besides $\\varepsilon$, the terminals are $a$ and $b$. The nonterminals are $S$, $T$ and $U$, $S$ being the starting symbol. The grammar is represented as follows.\n",
    "\n",
    "$S \\rightarrow U\\ |\\ V$  \n",
    "$U \\rightarrow TaU\\ |\\ TaT$  \n",
    "$V \\rightarrow TbV\\ |\\ TbT$  \n",
    "$T \\rightarrow aTbT\\ |\\ bTaT\\ |\\ \\varepsilon$\n",
    "\n",
    "To see that the language of this grammar is the set of finite sequences of $a$'s and $b$'s with an unequal number of $a$'s and $b$'s, read the four lines in the grammar's representation as follows: \n",
    "\n",
    "* Line 1: a string with an unequal number of $a$'s and $b$'s is a string with more $a$'s or a string with more $b$'s.\n",
    "* Line 2: a string with more $a$'s than $b$'s has a smallest initial segment with more $a$'s; this initial segment ends in $a$, has an equal number of $a$'s and $b$'s before that last occurrence of $a$, and is followed by a string with a number of occurrences of $a$'s at least equal to the number of occurrences of $b$'s.\n",
    "* Line 3: a string with more $b$'s than $a$'s has a smallest initial segment with more $b$'s; this initial segment ends in $b$, has an equal number of $a$'s and $b$'s before that last occurrence of $b$, and is followed by a string with a number of occurrences of $b$'s at least equal to the number of occurrences of $a$'s.\n",
    "* Line 4: a nonempty string with an equal number of $a$'s and $b$'s either starts with $a$ or with $b$. If it starts with $a$, that initial $a$ is followed by a smallest substring with a number of occurrences of $b$ equal to 1 plus the number of occurrences of $a$; such a substring ends in $b$, has an equal number of $a$'s and $b$'s before that last occurrence of $b$, and is followed by a string with a number of occurrences of $a$'s equal to the number of occurrences of $b$'s. If it starts with $b$, that initial $b$ is followed by a smallest substring with a number of occurrences of $a$ equal to 1 plus the number of occurrences of $b$; such a substring ends in $a$, has an equal number of $a$'s and $b$'s before that last occurrence of $a$, and is followed by a string with a number of occurrences of $a$'s equal to the number of occurrences of $b$'s.\n",
    "\n",
    "The reading shows that every string over $\\{a,b\\}$ with an unequal number of $a$'s and $b$'s is generated by the grammar. It is easy to verify that conversely, any string over $\\{a,b\\}$ that is generated by the grammar has an unequal number of $a$'s and $b$'s.\n",
    "\n",
    "Some strings over $\\{a,b\\}$ with an unequal number of $a$'s and $b$'s have many leftmost derivations. For instance, $aba$ has two:\n",
    "* $S \\rightarrow U \\rightarrow TaT \\rightarrow aT \\rightarrow abTaT \\rightarrow abaT \\rightarrow aba$\n",
    "* $S \\rightarrow U \\rightarrow TaT \\rightarrow aTbTaT \\rightarrow abTaT \\rightarrow abaT \\rightarrow aba$\n",
    "\n",
    "For other examples, here are some leftmost derivations of $abbabaaab$ and $bbbbaa$, preceded with visualisations that illustrate how to obtain them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\begin{array}{ccccccccccccccccccc}\n",
    "  & a &   & b &   & b &   & a &   & b &   & a &   & a &   & a &   & b &   \\\\\n",
    "S &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "U &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "T &   &   &   &   &   &   &   &   &   &   &   &   & a & T &   &   &   &   \\\\\n",
    "  & a & T & b & T &   &   &   &   &   &   &   &   & a & T &   &   &   &   \\\\\n",
    "  & a &   & b & T &   &   &   &   &   &   &   &   & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b & T & a & T &   &   &   &   & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b &   & a & T &   &   &   &   & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b &   & a &   & b & T & a & T & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b &   & a &   & b &   & a & T & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b &   & a &   & b &   & a &   & a & T &   &   &   &   \\\\\n",
    "  & a &   & b &   & b &   & a &   & b &   & a &   & a &   & a & T & b & T \\\\\n",
    "  & a &   & b &   & b &   & a &   & b &   & a &   & a &   & a &   & b & T \\\\\n",
    "  & a &   & b &   & b &   & a &   & b &   & a &   & a &   & a &   & b &\n",
    "\\end{array}$\n",
    "\n",
    "$S\\rightarrow U \\rightarrow TaT \\rightarrow aTbTaT \\rightarrow abTaT \\rightarrow abbTaTaT \\rightarrow abbaTaT \\rightarrow abbabTaTaT \\rightarrow abbabaTaT \\rightarrow abbabaaT \\rightarrow abbabaaaTbT \\rightarrow abbabaaabT \\rightarrow abbabaaab$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{array}{ccccccccccccccccc}\n",
    "  & b &   & b &   & b &   & b &   & a &   & a &   \\\\\n",
    "S &   &   &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "V &   &   &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "T & b & V &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "  & b & V &   &   &   &   &   &   &   &   &   &   \\\\\n",
    "  & b & T & b & T &   &   &   &   &   &   &   &   \\\\\n",
    "  & b &   & b & T &   &   &   &   &   &   &   &   \\\\\n",
    "  & b &   & b &   & b & T &   &   &   &   & a & T \\\\\n",
    "  & b &   & b &   & b &   & b & T & a & T & a & T \\\\\n",
    "  & b &   & b &   & b &   & b &   & a & T & a & T \\\\\n",
    "  & b &   & b &   & b &   & b &   & a &   & a & T \\\\\n",
    "  & b &   & b &   & b &   & b &   & a &   & a &\n",
    "\\end{array}$\n",
    "\n",
    "$S \\rightarrow V \\rightarrow TbV \\rightarrow bV \\rightarrow bTbT \\rightarrow bbT \\rightarrow bbbTaT \\rightarrow bbbbTaaT \\rightarrow bbbbaaT \\rightarrow bbbbaa$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uppercase and lowercase alphabetic characters will play the role of nonterminals and terminals, respectively. For $\\varepsilon$, it is convenient to use `ε`, which is an alphabetic character, hence can be part of a Python identifier or be an identifier by itself. Since $\\varepsilon$ represents the empty symbol, we initialise `ε` to the empty string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ε'.isalpha()\n",
    "\n",
    "ε = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is natural to capture the representation of $\\mathcal G$'s set of production rules as a dictionary, whose keys are the nonterminals, and whose values are the sets of strings that capture the right hand sides of the production rules with a given left hand side. The starting symbol is a one of the keys. Let us for some time fix $\\mathcal G$'s production rules and starting symbol to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {'J': {'a', 'b', 'c'}, 'D': {'H', 'ab'}, 'B': {'EH'}, 'I': {'IC'},\n",
    "         'H': {ε}, 'S': {'BG', 'b'}, 'G': {'a', ε, 'Sbc'}, 'F': {'Cd'},\n",
    "         'E': {'GH', 'GFHGa'}, 'C': {'a', 'bc'}, 'A': {'FI', 'J'}\n",
    "        }\n",
    "\n",
    "starting_symbol = 'S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write code to display $\\mathcal G$'s representation. We intend to display first the line for the starting symbol, then the lines for all other nonterminals in alphabetical order. For a given nonterminal, we intend to display the right hand sides of the production rules having that nonterminal as left hand side in lexicographic order. The following generator function yields the nonterminals as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ordered_nonterminals():\n",
    "    yield starting_symbol\n",
    "    yield from sorted(rules.keys() - {starting_symbol})\n",
    "\n",
    "list(ordered_nonterminals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ε__, which evaluates to the empty string, needs to be treated specially to be properly displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ε', 'Sbc', 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[production or 'ε' for production in sorted(rules['G'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fragment first displays what sits to the right of $\\rightarrow$ on the line for the nonterminal $G$, then the whole line for the nonterminal $G$, then the whole representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ε | Sbc | a\n",
      "\n",
      "G -> ε | Sbc | a\n",
      "\n",
      "S -> BG | b\n",
      "A -> FI | J\n",
      "B -> EH\n",
      "C -> a | bc\n",
      "D -> H | ab\n",
      "E -> GFHGa | GH\n",
      "F -> Cd\n",
      "G -> ε | Sbc | a\n",
      "H -> ε\n",
      "I -> IC\n",
      "J -> a | b | c\n"
     ]
    }
   ],
   "source": [
    "print(' | '.join(production or 'ε' for production in sorted(rules['G'])))\n",
    "print()\n",
    "\n",
    "print(' -> '.join(('G', ' | '.join(production or 'ε'\n",
    "                                       for production in sorted(rules['G'])\n",
    "                                  )\n",
    "                  )\n",
    "                 )\n",
    "     )\n",
    "print()\n",
    "      \n",
    "print('\\n'.join(' -> '.join((f'{nonterminal}',\n",
    "                             ' | '.join(production or 'ε' for production in\n",
    "                                                     sorted(rules[nonterminal])\n",
    "                                       )\n",
    "                            )\n",
    "                           ) for nonterminal in ordered_nonterminals()\n",
    "               )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us for a moment get back to $\\mathcal G$ being arbitrary. Clearly, the empty sequence belongs to the language of $\\mathcal G$ only if $\\varepsilon$ is involved in $\\mathcal G$'s set of production rules. It turns out that any other member of the language of $\\mathcal G$ does not need $\\varepsilon$ to be generated: in case it appears in $\\mathcal G$'s set of production rules, $\\varepsilon$ can be eliminated, resulting in a new set of production rules for a grammar whose language does not contain the empty sequence where the language of $\\mathcal G$ might, but otherwise is the language of $\\mathcal G$.\n",
    "\n",
    "The elimination of $\\varepsilon$ proceeds in two stages, and is easily verified to correctly produce a set of production rules not involving $\\varepsilon$ for a CFG whose language is the language of $\\mathcal G$, with the possible exception of the empty sequence. Let $\\mathcal G'$ denote that CFG derived from $\\mathcal G$.\n",
    "\n",
    "* In the first stage, one identifies the set $\\mathfrak S_1$ of nonterminals that produce $\\varepsilon$ directly (so the nonterminals $\\alpha$ such that one of the production rules of $\\mathcal G$ maps $\\alpha$ to $\\varepsilon$), then the set $\\mathfrak S_2$ of nonterminals that produce a sequence of symbols that all belong to $\\mathfrak S_1$, then the set $\\mathfrak S_3$ of nonterminals that produce a sequence of symbols that all belong to $\\mathfrak S_2$... until no new nonterminal is discovered. Denote by $\\mathfrak S$ the resulting set of nonterminals.\n",
    "* In the second stage, for all production rules $\\mathcal R$ of $\\mathcal G$ that map a nonterminal $\\alpha$ to a sequence of symbols $\\beta_0\\dots\\beta_n$, any occurrence of $\\beta_i$, $i\\leq n$, that belongs to $\\mathfrak S$, is either kept or eliminated in the production rules of $\\mathcal G'$ that correspond to $\\mathcal R$. Hence if a production rule $\\mathcal R$ of $\\mathcal G$ has $k$ occurrences of a member of $\\mathfrak S$ on its right hand side, then $\\mathcal G'$ has $2^k$ production rules that correspond to $\\mathcal R$.\n",
    "\n",
    "Let us again fix $\\mathcal G$'s production rules and starting symbol as we did above. It is then easy to verify that $\\mathfrak S=\\{G, H, E, D, B, S\\}$, and that since both $G$ and $H$ belong to $\\mathfrak S$, the production rule that maps $E$ to $GFHGa$ correspondingly has:\n",
    "\n",
    "* one production rule that maps $E$ to $GFHGa$;\n",
    "* one production rule that maps $E$ to $GFHa$;\n",
    "* one production rule that maps $E$ to $GFGa$;\n",
    "* one production rule that maps $E$ to $GFa$;\n",
    "* one production rule that maps $E$ to $FHGa$;\n",
    "* one production rule that maps $E$ to $FHa$;\n",
    "* one production rule that maps $E$ to $FGa$;\n",
    "* one production rule that maps $E$ to $Fa$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fragment implements the first stage, tracing execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonterminals now known to generate ε: set()\n",
      "Nonterminals left to (re)examine: dict_keys(['J', 'D', 'B', 'I', 'H', 'S', 'G', 'F', 'E', 'C', 'A'])\n",
      "  Considering J -> a | b | c ... \n",
      "  Considering D -> H | ab ... \n",
      "  Considering B -> EH ... \n",
      "  Considering I -> IC ... \n",
      "  Considering H -> ε ... found out to generate ε\n",
      "  Considering S -> BG | b ... \n",
      "  Considering G -> ε | Sbc | a ... found out to generate ε\n",
      "  Considering F -> Cd ... \n",
      "  Considering E -> GFHGa | GH ... found out to generate ε\n",
      "  Considering C -> a | bc ... \n",
      "  Considering A -> FI | J ... \n",
      "\n",
      "Nonterminals now known to generate ε: {'E', 'G', 'H'}\n",
      "Nonterminals left to (re)examine: {'I', 'A', 'C', 'B', 'D', 'J', 'F', 'S'}\n",
      "  Considering I -> IC ... \n",
      "  Considering A -> FI | J ... \n",
      "  Considering C -> a | bc ... \n",
      "  Considering B -> EH ... found out to generate ε\n",
      "  Considering D -> H | ab ... found out to generate ε\n",
      "  Considering J -> a | b | c ... \n",
      "  Considering F -> Cd ... \n",
      "  Considering S -> BG | b ... found out to generate ε\n",
      "\n",
      "Nonterminals now known to generate ε: {'G', 'B', 'D', 'E', 'S', 'H'}\n",
      "Nonterminals left to (re)examine: {'I', 'A', 'C', 'J', 'F'}\n",
      "  Considering I -> IC ... \n",
      "  Considering A -> FI | J ... \n",
      "  Considering C -> a | bc ... \n",
      "  Considering J -> a | b | c ... \n",
      "  Considering F -> Cd ... \n"
     ]
    }
   ],
   "source": [
    "generating_ε = set()\n",
    "left_to_examine = rules.keys()\n",
    "while True:\n",
    "    print('Nonterminals now known to generate ε:', generating_ε)\n",
    "    print('Nonterminals left to (re)examine:', left_to_examine)\n",
    "    new_nonterminals_generating_ε = set()\n",
    "    for nonterminal in left_to_examine:\n",
    "        print(f'  Considering {nonterminal}',\n",
    "              ' | '.join(production or 'ε'\n",
    "                             for production in sorted(rules[nonterminal])\n",
    "                       ), sep=' -> ', end=' ... '\n",
    "             )\n",
    "        if any(production == '' or set(production) <= generating_ε\n",
    "                   for production in rules[nonterminal]\n",
    "              ):\n",
    "            print('found out to generate ε')\n",
    "            generating_ε.add(nonterminal)\n",
    "            new_nonterminals_generating_ε.add(nonterminal)\n",
    "        else:\n",
    "            print()\n",
    "    if new_nonterminals_generating_ε:\n",
    "        left_to_examine -= generating_ε\n",
    "        print()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second stage, rules whose right hand side does not contain any nonterminal in $\\mathfrak S$ are taken as such. For all other production rules $\\mathcal R$ of $\\mathcal G$, it is convenient to use the `product` class from the `itertools` module to generate all possible right hand sides of the rules that correspond to $\\mathcal R$ in $\\mathcal G'$. For the production rule that maps $E$ to $GFGHa$, with both $G$ and $H$ but not $F$ belonging to $\\mathfrak S$, the right hand sides of the corresponding rules of $\\mathcal G'$ can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 'F', 'H', 'G', 'a'),\n",
       " ('G', 'F', 'H', '', 'a'),\n",
       " ('G', 'F', '', 'G', 'a'),\n",
       " ('G', 'F', '', '', 'a'),\n",
       " ('', 'F', 'H', 'G', 'a'),\n",
       " ('', 'F', 'H', '', 'a'),\n",
       " ('', 'F', '', 'G', 'a'),\n",
       " ('', 'F', '', '', 'a')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['GFHGa', 'GFHa', 'GFGa', 'GFa', 'FHGa', 'FHa', 'FGa', 'Fa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product(*((symbol, '') if symbol in generating_ε else (symbol,)\n",
    "                   for symbol in ('G', 'F', 'H', 'G', 'a')\n",
    "              )\n",
    "            )\n",
    "    )\n",
    "\n",
    "[''.join(symbols) for symbols in product(\n",
    "        *((symbol, '') if symbol in generating_ε else (symbol,)\n",
    "              for symbol in ('G', 'F', 'H', 'G', 'a')\n",
    "         )\n",
    "                                        )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fragment uses this technique and implements the second stage, tracing execution. When a rule $\\mathcal R$ is produced that has an empty right hand side (because it comes from a rule of $\\mathcal G$ whose right hand side consists of nothing but nonterminals in $\\mathfrak S$ and none of those terminals is kept, then $\\mathcal R$ is eventually deleted. When for a given nonterminal $\\alpha$, all produced rules with $\\alpha$ as left hand side have an empty right hand side and so are deleted, then the representation of $\\mathcal G'$ loses the line for $\\alpha$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rules to replace -> G -> ε | Sbc | a\n",
      "    New rules: G -> Sbc | a | bc\n",
      "Creating rules to replace -> B -> EH\n",
      "    New rules: B -> '' | E | EH | H\n",
      "Creating rules to replace -> D -> H | ab\n",
      "    New rules: D -> '' | H | ab\n",
      "Creating rules to replace -> E -> GFHGa | GH\n",
      "    New rules: E -> '' | FGa | FHGa | FHa | Fa | G | GFGa | GFHGa | GFHa | GFa | GH | H\n",
      "Creating rules to replace -> S -> BG | b\n",
      "    New rules: S -> '' | B | BG | G | b\n",
      "Creating rules to replace -> H -> ε\n",
      "    New rules: H -> ''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'J': {'a', 'b', 'c'},\n",
       " 'I': {'IC'},\n",
       " 'F': {'Cd'},\n",
       " 'C': {'a', 'bc'},\n",
       " 'A': {'FI', 'J'},\n",
       " 'G': {'Sbc', 'a', 'bc'},\n",
       " 'B': {'E', 'EH', 'H'},\n",
       " 'D': {'H', 'ab'},\n",
       " 'E': {'FGa',\n",
       "  'FHGa',\n",
       "  'FHa',\n",
       "  'Fa',\n",
       "  'G',\n",
       "  'GFGa',\n",
       "  'GFHGa',\n",
       "  'GFHa',\n",
       "  'GFa',\n",
       "  'GH',\n",
       "  'H'},\n",
       " 'S': {'B', 'BG', 'G', 'b'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_without_ε = {nonterminal: rules[nonterminal]\n",
    "                    for nonterminal in rules if nonterminal not in generating_ε\n",
    "                  }\n",
    "for nonterminal in generating_ε:\n",
    "    print('Creating rules to replace', nonterminal,\n",
    "          ' | '.join(production or 'ε'\n",
    "                         for production in sorted(rules[nonterminal])\n",
    "                    ), sep=' -> '\n",
    "         )\n",
    "    new_productions =\\\n",
    "        {''.join(symbols) for production in rules[nonterminal] if production\n",
    "                              for symbols in product(\n",
    "                        *((symbol, '') if symbol in generating_ε else (symbol,)\n",
    "                              for symbol in production\n",
    "                         )\n",
    "                                                    )\n",
    "        }\n",
    "    print('    New rules:', nonterminal, '-> ', end='')\n",
    "    if new_productions:\n",
    "        print(' | '.join(production or \"''\"\n",
    "                             for production in sorted(new_productions)\n",
    "                        )\n",
    "             )\n",
    "    else:\n",
    "        print(\"''\")\n",
    "    new_productions -= {''}\n",
    "    if new_productions:\n",
    "        rules_without_ε[nonterminal] = new_productions\n",
    "    \n",
    "rules_without_ε"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us for a moment get back to $\\mathcal G$ being arbitrary. A natural question is whether, given a finite sequence $\\Lambda$ of terminals, $\\mathcal G$ generates $\\Lambda$. It $\\Lambda$ is empty, then it suffices to check whether $\\mathcal G$'s starting symbol belongs to $\\mathfrak S$. If $\\Lambda$ is not empty, then it is equivalent to ask whether $\\Lambda$ is generated by $\\mathcal G'$. This makes the question easier to answer: if $\\varepsilon$ is present in some production rules of $\\mathcal G$, then a derivation of $\\Lambda$ by $\\mathcal G$ might involve arbitrarily long sequences of symbols, because any symbol in $\\mathfrak S$ can eventually be erased. On the other hand, in any derivation of $\\mathcal G'$, sequences of symbols can only increase in size as the derivation progresses. Since the number of sequences of terminals and nonterminals of a CFG of a given size is finite, the search for a derivation of $\\Lambda$ can be exhaustive and yield a definite outcome in finite time. The search can be reduced to leftmost derivations.\n",
    "\n",
    "Still, it is of interest to ask the more general question: given a nonempty finite sequence $\\Lambda$ of terminals, does $\\mathcal G$ generate $\\Lambda$ without making use of $\\varepsilon$? Then one can ask whether $\\mathcal G'$ generates $\\Lambda$ without making use of $\\varepsilon$, which is the same as asking whether $\\mathcal G'$ generates $\\Lambda$, which is equivalent to asking whether $\\mathcal G$ generates $\\Lambda$.\n",
    "\n",
    "The method is the following. We work with pairs $(w_1,w_2)$ with $w_1$ a sequence of terminals and $w_2$ a sequence of  nonterminals and terminals. Only pairs where $w_1$ is an initial segment of $\\Lambda$ are \"promising\". The aim is to eventually generate $(\\Lambda, \\varepsilon)$. A set $\\mathfrak A$ keeps track of all promising pairs that have been generated, and a subset $\\mathfrak B$ of $\\mathfrak A$ keeps track of the pairs on which we can further operate. We start with $\\mathfrak A$ and $\\mathfrak B$ containing $(S, \\epsilon)$ only with $S$ denoting $\\mathcal G$'s starting symbol, and we proceed in stages. At any given stage, if $\\mathfrak B$ is empty, then one declares that $\\Lambda$ cannot be generated; otherwise, one gets a pair $(w_1,w_2)$ out of $\\mathfrak B$ and move from the left of $w_2$ to the right of $w_1$ the longest initial segment of $w_2$ consisting of terminals, resulting in a pair $(w'_1,w'_2)$ with $w'_2$ empty or starting with a nonterminal $\\alpha$.\n",
    "\n",
    "* If $w'_1$ is not an initial segment of $\\Lambda$, then $(w'_1,w'_2)$ has a bad start.\n",
    "* Otherwise, if $w'_2$ is empty, then either $w'_1$ is $\\Lambda$ and known to be generated by $\\mathcal G$ without using $\\varepsilon$ and we are done, or $w'_1$ is not $\\Lambda$ (which is equivalent to $w'_1$ being shorted than $\\Lambda$), so not what we want.\n",
    "* Otherwise, we consider all production rules of $\\mathcal G$ with $\\alpha$ as left hand side and not $\\varepsilon$ as right hand side. For each such rule, we replace in $w'_2$ the occurrence of $\\alpha$ on the left with the rule's right hand side, resulting in a new pair $(w'_1, w''_2)$.\n",
    "    * If the combined length of $w'_1$ and $w''_2$ is longer than the length of $\\Lambda$, then $(w'_1, w''_2)$ is too long.\n",
    "    * If $(w'_1, w''_2)$ belongs to $\\mathfrak A$, then it has been seen already.\n",
    "    * Otherwise, $(w'_1, w''_2)$ is \"promising\", recorded in $\\mathfrak A$ as seen, and in $\\mathfrak B$ for potential further consideration.\n",
    "    \n",
    "The function that follows implements this method. Rather than a set, it uses a list for $\\mathfrak A$, and at every stage, pops its rightmost element, making the method a form of depth-first search. We trace execution with a CFG that generates the palindromes over $\\{a,b\\}$, defined with a little complication to easily witness the case where we process a pair that has been seen already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering ('', 'T') ... transformed to ('', 'T') ... ok\n",
      "  Looking at rule T -> U ... ('', 'U') to consider\n",
      "Considering ('', 'U') ... transformed to ('', 'U') ... ok\n",
      "  Looking at rule U -> T ... ('', 'T') already seen\n",
      "  Looking at rule U -> S ... ('', 'S') to consider\n",
      "Considering ('', 'S') ... transformed to ('', 'S') ... ok\n",
      "  Looking at rule S -> b ... ('', 'b') to consider\n",
      "  Looking at rule S -> a ... ('', 'a') to consider\n",
      "  Looking at rule S -> aSa ... ('', 'aSa') to consider\n",
      "  Looking at rule S -> bSb ... ('', 'bSb') to consider\n",
      "Considering ('', 'bSb') ... transformed to ('b', 'Sb') ... bad start\n",
      "Considering ('', 'aSa') ... transformed to ('a', 'Sa') ... ok\n",
      "  Looking at rule S -> b ... ('a', 'ba') to consider\n",
      "  Looking at rule S -> a ... ('a', 'aa') to consider\n",
      "  Looking at rule S -> aSa ... ('a', 'aSaa') to consider\n",
      "  Looking at rule S -> bSb ... ('a', 'bSba') to consider\n",
      "Considering ('a', 'bSba') ... transformed to ('ab', 'Sba') ... bad start\n",
      "Considering ('a', 'aSaa') ... transformed to ('aa', 'Saa') ... ok\n",
      "  Looking at rule S -> b ... ('aa', 'baa') to consider\n",
      "  Looking at rule S -> a ... ('aa', 'aaa') to consider\n",
      "  Looking at rule S -> aSa ... ('aa', 'aSaaa') too long\n",
      "  Looking at rule S -> bSb ... ('aa', 'bSbaa') too long\n",
      "Considering ('aa', 'aaa') ... transformed to ('aaaaa', '') ... bad start\n",
      "Considering ('aa', 'baa') ... transformed to ('aabaa', '') ... what I want!\n",
      "\n",
      "Considering ('', 'T') ... transformed to ('', 'T') ... ok\n",
      "  Looking at rule T -> U ... ('', 'U') to consider\n",
      "Considering ('', 'U') ... transformed to ('', 'U') ... ok\n",
      "  Looking at rule U -> T ... ('', 'T') already seen\n",
      "  Looking at rule U -> S ... ('', 'S') to consider\n",
      "Considering ('', 'S') ... transformed to ('', 'S') ... ok\n",
      "  Looking at rule S -> b ... ('', 'b') to consider\n",
      "  Looking at rule S -> a ... ('', 'a') to consider\n",
      "  Looking at rule S -> aSa ... ('', 'aSa') to consider\n",
      "  Looking at rule S -> bSb ... ('', 'bSb') to consider\n",
      "Considering ('', 'bSb') ... transformed to ('b', 'Sb') ... bad start\n",
      "Considering ('', 'aSa') ... transformed to ('a', 'Sa') ... ok\n",
      "  Looking at rule S -> b ... ('a', 'ba') to consider\n",
      "  Looking at rule S -> a ... ('a', 'aa') to consider\n",
      "  Looking at rule S -> aSa ... ('a', 'aSaa') to consider\n",
      "  Looking at rule S -> bSb ... ('a', 'bSba') to consider\n",
      "Considering ('a', 'bSba') ... transformed to ('ab', 'Sba') ... bad start\n",
      "Considering ('a', 'aSaa') ... transformed to ('aa', 'Saa') ... ok\n",
      "  Looking at rule S -> b ... ('aa', 'baa') to consider\n",
      "  Looking at rule S -> a ... ('aa', 'aaa') to consider\n",
      "  Looking at rule S -> aSa ... ('aa', 'aSaaa') too long\n",
      "  Looking at rule S -> bSb ... ('aa', 'bSbaa') too long\n",
      "Considering ('aa', 'aaa') ... transformed to ('aaaaa', '') ... bad start\n",
      "Considering ('aa', 'baa') ... transformed to ('aabaa', '') ... bad start\n",
      "Considering ('a', 'aa') ... transformed to ('aaa', '') ... bad start\n",
      "Considering ('a', 'ba') ... transformed to ('aba', '') ... bad start\n",
      "Considering ('', 'a') ... transformed to ('a', '') ... not what I want\n",
      "Considering ('', 'b') ... transformed to ('b', '') ... bad start\n",
      "Cannot be generated\n"
     ]
    }
   ],
   "source": [
    "def can_generate_with_no_ε(word):\n",
    "    generated_bigrams = [('', starting_symbol)]\n",
    "    seen_bigrams = set(generated_bigrams)\n",
    "    while generated_bigrams:\n",
    "        w_1, w_2 = generated_bigrams.pop()\n",
    "        print('Considering', (w_1, w_2), end=' ... ')\n",
    "        while w_2 and not w_2[0].isupper():\n",
    "            w_1, w_2 = w_1 + w_2[0], w_2[1: ]\n",
    "        print('transformed to', (w_1, w_2), end=' ... ')\n",
    "        if not word.startswith(w_1):\n",
    "            print('bad start')\n",
    "            continue\n",
    "        if not w_2:\n",
    "            if len(w_1) == len(word):\n",
    "                print('what I want!')\n",
    "                return\n",
    "            print('not what I want')\n",
    "            continue\n",
    "        print('ok')\n",
    "        for pattern in rules[w_2[0]]:\n",
    "            if not pattern:\n",
    "                continue\n",
    "            print('  Looking at rule', w_2[0], '->', pattern, end=' ... ')\n",
    "            new_bigram = w_1, pattern + w_2[1: ]\n",
    "            if len(new_bigram[0]) + len(new_bigram[1]) > len(word):\n",
    "                print(new_bigram, 'too long')\n",
    "                continue\n",
    "            if new_bigram in seen_bigrams:\n",
    "                print(new_bigram, 'already seen')\n",
    "                continue\n",
    "            generated_bigrams.append(new_bigram)\n",
    "            seen_bigrams.add(new_bigram)\n",
    "            print(new_bigram, 'to consider')\n",
    "    print('Cannot be generated')\n",
    "\n",
    "rules = {'T': {'U'}, 'U': {'T', 'S'}, 'S': {'aSa', 'bSb', 'a', 'b', ε}}\n",
    "starting_symbol = 'T'\n",
    "\n",
    "can_generate_with_no_ε('aabaa')\n",
    "print()\n",
    "\n",
    "can_generate_with_no_ε('aabbaa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us organise the whole code in a class `ContextFreeGrammar`, whose `__init()__` method receives as arguments the dictionary capturing the production rules and the starting symbol of $\\mathcal G$. It is natural to let `__init()__` compute once and for all whether $\\mathcal G$ generates the empty sequence, and also compute $\\mathcal G'$. We want `ContextFreeGrammar` to define a method `can_generate_with_no_ε()`, meant to be passed as argument a string of terminal symbols to determine whether $\\mathcal G$ can generate this sequence without making any use of $\\varepsilon$, which is interesting in its own right. We also want `ContextFreeGrammar` to define a method `can_generate()`, meant to be passed as argument a string of terminal symbols to determine whether $\\mathcal G$ generates this sequence, which we know is work for $\\mathcal G'$. This suggests defining another class, `ContextFreeGrammarWithoutε`, able to complete the work required by `ContextFreeGrammar`'s `can_generate()` method, which is precisely what `ContextFreeGrammar`'s `can_generate_with_no_ε()` method does when no production rule involves $\\varepsilon$. Though `ContextFreeGrammarWithoutε` seems to be a more specific type than `ContextFreeGrammar`, it would not be appropriate to let the `__init()__` method of `ContextFreeGrammarWithoutε` compute whether the empty sequence can be generated (the answer is No), nor compute a grammar not involving $\\varepsilon$ and generating the same language (empty sequence included), since `self` could just be returned. So we do not want `ContextFreeGrammarWithoutε`'s `__init()__` method to call `ContextFreeGrammar`'s `__init()__` method. We only want `ContextFreeGrammarWithoutε` to inherit some of `ContextFreeGrammar`'s methods: `__str()__` if that method has been defined to nicely output the grammar's representation, and `can_generate()`, whose implementation should be straightforward and just call `ContextFreeGrammar`'s `can_generate_with_no_ε()` method, so more precisely, overwrite `ContextFreeGrammar`'s implementation of `can_generate()`, which itself essentially calls `ContextFreeGrammarWithoutε`'s `can_generate()` method on the object produced by `__init()__`'s computation of $\\mathcal G'$. This design makes `ContextFreeGrammar` a mixin of `ContextFreeGrammarWithoutε`. The syntax is `class ContextFreeGrammarWithoutε(ContextFreeGrammar)`, but it does not intend to make a `ContextFreeGrammarWithoutε` object a kind of `ContextFreeGrammar` object: rather, it just intends a `ContextFreeGrammarWithoutε` object to make use by inheritance of the `ContextFreeGrammar` methods that make sense to a `ContextFreeGrammarWithoutε` object, such as `can_generate()`, but not of those that are irrelevant, such as `can_generate_with_no_ε()`.\n",
    "\n",
    "To summarise, the key design of `ContextFreeGrammar` and `ContextFreeGrammarWithoutε` is outlined below. The syntax `class ContextFreeGrammarWithoutε(ContextFreeGrammar)` is meant to be read as: `ContextFreeGrammarWithoutε` is a subclass of `object` that can use methods of `ContextFreeGrammar` when appropriate. The fact that `ContextFreeGrammarWithoutε`'s `__init()__` method does not call `ContextFreeGrammar`'s `__init()__` method might be the best formal indicator that `ContextFreeGrammar` is a mixin of `ContextFreeGrammarWithoutε`, not a genuine parent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextFreeGrammar:\n",
    "    def __init__(self, rules, starting_symbol):\n",
    "        self.rules = rules\n",
    "        self.starting_symbol = starting_symbol\n",
    "        # Compute self._starting_symbol_generates_ε (True or False).\n",
    "        # Compute self.with_ε_eliminated (a CFG making no use of ε and\n",
    "        # generating the same language, with the possible exception of\n",
    "        # the empty sequence).\n",
    "\n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "    def can_generate_with_no_ε(self, word):\n",
    "        pass\n",
    "    \n",
    "    def can_generate(self, word):\n",
    "        if word == '':\n",
    "            return self._starting_symbol_generates_ε\n",
    "        return self.with_ε_eliminated.can_generate(word)\n",
    "\n",
    "\n",
    "class ContextFreeGrammarWithoutε(ContextFreeGrammar):\n",
    "    def __init__(self, rules, starting_symbol):\n",
    "        self.rules = rules\n",
    "        self.starting_symbol = starting_symbol\n",
    "\n",
    "    def can_generate(self, word):\n",
    "        return self.can_generate_with_no_ε(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting things together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextFreeGrammar:\n",
    "    def __init__(self, rules, starting_symbol):\n",
    "        self.rules = rules\n",
    "        self.starting_symbol = starting_symbol\n",
    "        generating_ε = self._generates_ε()\n",
    "        self._starting_symbol_generates_ε = starting_symbol in generating_ε\n",
    "        rules_without_ε = {nonterminal: rules[nonterminal]\n",
    "                               for nonterminal in rules\n",
    "                                   if nonterminal not in generating_ε\n",
    "                          }\n",
    "        for nonterminal in generating_ε:\n",
    "            new_productions =\\\n",
    "          {''.join(symbols) for production in rules[nonterminal] if production\n",
    "                                for symbols in product(\n",
    "                        *((symbol, '') if symbol in generating_ε else (symbol,)\n",
    "                              for symbol in production\n",
    "                         )\n",
    "                                                      )\n",
    "          }\n",
    "            new_productions -= {''}\n",
    "            if new_productions:\n",
    "                rules_without_ε[nonterminal] = new_productions\n",
    "        self.without_ε = ContextFreeGrammarWithoutε(rules_without_ε,\n",
    "                                                    self.starting_symbol\n",
    "                                                   )\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(' -> '.join((f'{nonterminal}',\n",
    "                                      ' | '.join(production or 'ε'\n",
    "                                                     for production in\n",
    "                                                sorted(self.rules[nonterminal])\n",
    "                                                )\n",
    "                                     )\n",
    "                                    ) for nonterminal in\n",
    "                                                   self._ordered_nonterminals()\n",
    "                        )\n",
    "\n",
    "    def _ordered_nonterminals(self):\n",
    "        yield self.starting_symbol\n",
    "        yield from sorted(self.rules.keys() - {self.starting_symbol})\n",
    "        \n",
    "    def _generates_ε(self):\n",
    "        generating_ε = set()\n",
    "        left_to_examine = self.rules.keys()\n",
    "        while True:\n",
    "            new_nonterminals_generating_ε = set()\n",
    "            for nonterminal in left_to_examine:\n",
    "                if any(production == '' or set(production) <= generating_ε\n",
    "                           for production in self.rules[nonterminal]\n",
    "                      ):\n",
    "                    generating_ε.add(nonterminal)\n",
    "                    new_nonterminals_generating_ε.add(nonterminal)\n",
    "            if new_nonterminals_generating_ε:\n",
    "                left_to_examine -= new_nonterminals_generating_ε\n",
    "            else:\n",
    "                break\n",
    "        return generating_ε\n",
    "\n",
    "    def can_generate_with_no_ε(self, word):\n",
    "        if word == '':\n",
    "            return False\n",
    "        generated_bigrams = [('', self.starting_symbol)]\n",
    "        seen_bigrams = set(generated_bigrams)\n",
    "        while generated_bigrams:\n",
    "            w_1, w_2 = generated_bigrams.pop()\n",
    "            while w_2 and not w_2[0].isupper():\n",
    "                w_1, w_2 = w_1 + w_2[0], w_2[1 :]\n",
    "            if not word.startswith(w_1):\n",
    "                continue\n",
    "            if not w_2:\n",
    "                if len(w_1) == len(word):\n",
    "                    return True\n",
    "                continue\n",
    "            for pattern in self.rules[w_2[0]]:\n",
    "                if not pattern:\n",
    "                    continue\n",
    "                new_bigram = w_1, pattern + w_2[1 :]\n",
    "                if len(new_bigram[0]) + len(new_bigram[1]) <= len(word)\\\n",
    "                   and new_bigram not in seen_bigrams:\n",
    "                    generated_bigrams.append(new_bigram)\n",
    "                    seen_bigrams.add(new_bigram)\n",
    "        return False\n",
    "\n",
    "    def can_generate(self, word):\n",
    "        if word == '':\n",
    "            return self._starting_symbol_generates_ε\n",
    "        return self.without_ε.can_generate(word)\n",
    "\n",
    "\n",
    "class ContextFreeGrammarWithoutε(ContextFreeGrammar):\n",
    "    def __init__(self, rules, starting_symbol):\n",
    "        self.rules = rules\n",
    "        self.starting_symbol = starting_symbol\n",
    "\n",
    "    def can_generate(self, word):\n",
    "        return self.can_generate_with_no_ε(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> ε | a | aSa | b | bSb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {'S': {'aSa', 'bSb', 'a', 'b', ε}}\n",
    "starting_symbol = 'S'\n",
    "\n",
    "CFG = ContextFreeGrammar(rules, starting_symbol)\n",
    "print(CFG)\n",
    "CFG.can_generate_with_no_ε('ababa')\n",
    "CFG.can_generate_with_no_ε('abaaba')\n",
    "CFG.can_generate('')\n",
    "CFG.can_generate('abaaba')\n",
    "CFG.can_generate('abaabba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> A | bSbb\n",
      "A -> ε | aA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {'S': {'bSbb', 'A'}, 'A': {'aA', ε}}\n",
    "starting_symbol = 'S'\n",
    "\n",
    "CFG = ContextFreeGrammar(rules, starting_symbol)\n",
    "print(CFG)\n",
    "CFG.can_generate_with_no_ε('bbaabbbb')\n",
    "CFG.can_generate('')\n",
    "CFG.can_generate('bbaabbbb')\n",
    "CFG.can_generate('bbbaabbbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> () | (S) | SS | [S] | []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {'S': {'SS', '()', '(S)', '[]', '[S]'}}\n",
    "starting_symbol = 'S'\n",
    "\n",
    "CFG = ContextFreeGrammar(rules, starting_symbol)\n",
    "print(CFG)\n",
    "CFG.can_generate('')\n",
    "CFG.can_generate('([][()])[()]()')\n",
    "CFG.can_generate('([][(])[()]()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> U | V\n",
      "T -> ε | aTbT | bTaT\n",
      "U -> TaT | TaU\n",
      "V -> TbT | TbV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {'S': {'U', 'V'}, 'U': {'TaU', 'TaT'}, 'V': {'TbV', 'TbT'},\n",
    "         'T': {'aTbT', 'bTaT', ε}\n",
    "        }\n",
    "starting_symbol = 'S'\n",
    "\n",
    "CFG = ContextFreeGrammar(rules, starting_symbol)\n",
    "print(CFG)\n",
    "CFG.can_generate('')\n",
    "CFG.can_generate('abbbbabaa')\n",
    "CFG.can_generate('abbbabaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
